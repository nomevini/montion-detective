{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c858b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def seconds_to_time(seconds):\n",
    "    hours = seconds // 3600  # Integer number of hours\n",
    "    remaining_seconds = seconds % 3600  # Seconds remaining after hours\n",
    "\n",
    "    minutes = remaining_seconds // 60  # Integer number of minutes\n",
    "    final_seconds = remaining_seconds % 60  # Seconds remaining after minutes\n",
    "\n",
    "    time = datetime.time(hours, minutes, final_seconds)\n",
    "    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a047d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular o tempo que cada deteccao esteve no video\n",
    "def video_detection_time(frames_counter, video_fps):\n",
    "    if frames_counter is not None:\n",
    "        detection_time = {}\n",
    "        \n",
    "        for id, qtde_frames in frames_counter.items():\n",
    "            seconds = qtde_frames / fps\n",
    "            detection_time[id] = seconds_to_time(seconds)\n",
    "            \n",
    "        return detection_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4ca711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "image 1/1 /home/nomevini/Documentos/Iniciação Cientifica/Projeto/tracking_people_in_videos/app/yolov8/print.png: 384x640 13 persons, 106.2ms\n",
      "Speed: 1.0ms preprocess, 106.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# calcular o tempo que cada deteccao permaneceu no vídeo\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m video_detection_time \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_detection_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_detect_counter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Libera os objetos do vídeo e fecha a janela\u001b[39;00m\n\u001b[1;32m     73\u001b[0m input_video\u001b[38;5;241m.\u001b[39mrelease()\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mvideo_detection_time\u001b[0;34m(frames_counter, video_fps)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, qtde_frames \u001b[38;5;129;01min\u001b[39;00m frames_counter\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m     seconds \u001b[38;5;241m=\u001b[39m qtde_frames \u001b[38;5;241m/\u001b[39m fps\n\u001b[0;32m----> 8\u001b[0m     detection_time[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mseconds_to_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m detection_time\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mseconds_to_time\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m      7\u001b[0m minutes \u001b[38;5;241m=\u001b[39m remaining_seconds \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m  \u001b[38;5;66;03m# Integer number of minutes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m final_seconds \u001b[38;5;241m=\u001b[39m remaining_seconds \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m60\u001b[39m  \u001b[38;5;66;03m# Seconds remaining after minutes\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhours\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminutes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_seconds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "    thickness=2,\n",
    "    text_thickness=1,\n",
    "    text_scale=0.5\n",
    ")\n",
    "\n",
    "model_name = \"yolov8n.pt\"\n",
    "video_path = \"/home/nomevini/Documentos/Iniciação Cientifica/Projeto/tracking_people_in_videos/app/yolov8/people-walking-640x360.mp4\"\n",
    "\n",
    "model = YOLO(model_name)\n",
    "\n",
    "# Abre o vídeo de entrada e obtem as configurações\n",
    "input_video = cv2.VideoCapture(video_path)\n",
    "fps = input_video.get(cv2.CAP_PROP_FPS)\n",
    "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define o codec e as configurações do vídeo de saída\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# contar os frames que cada deteccao apareceu\n",
    "frames_detect_counter = {}\n",
    "\n",
    "for result in model.track(source=video_path, stream=True, agnostic_nms=True, classes=[0]):\n",
    "    frame = result.orig_img\n",
    "    detections = sv.Detections.from_yolov8(result)\n",
    "\n",
    "    if result.boxes.id is not None:\n",
    "        detections.tracker_id = result.boxes.id.cpu().numpy().astype(int)\n",
    "        \n",
    "        # contar todas as deteccoes do frame\n",
    "        for identifier in result.boxes.id:\n",
    "            id_int = int(identifier)\n",
    "            if id_int in frames_detect_counter.keys(): \n",
    "                frames_detect_counter[id_int] = frames_detect_counter[id_int] + 1\n",
    "            else:\n",
    "                frames_detect_counter[id_int] = 1\n",
    "\n",
    "    detections = detections[(detections.class_id == 0)]\n",
    "\n",
    "    \n",
    "    labels = [\n",
    "        f\"{tracker_id} {confidence:0.2f}\"\n",
    "        for _, confidence , _, tracker_id\n",
    "        in detections\n",
    "    ]\n",
    "\n",
    "    frame = box_annotator.annotate(\n",
    "        scene=frame, \n",
    "        detections=detections,\n",
    "        labels=labels\n",
    "    )\n",
    "\n",
    "    # Escreve o quadro processado no arquivo de vídeo de saída\n",
    "    output_video.write(frame)\n",
    "    cv2.imwrite('nova_imagem.png', frame)\n",
    "    \n",
    "    cv2.imshow(model_name, frame)\n",
    "\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "        break\n",
    "        \n",
    "# calcular o tempo que cada deteccao permaneceu no vídeo\n",
    "video_detection_time = video_detection_time(frames_detect_counter, fps)\n",
    "\n",
    "# Libera os objetos do vídeo e fecha a janela\n",
    "input_video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dba455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O maximo id registrado corresponde a quantidade de pessoas que passaram pelo video\n",
    "qtde_pessoas = int(max(result.boxes.id))\n",
    "qtde_pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada boxes desse corresponde a uma das detecções daqueles frame\n",
    "# cada posição nessa detecção corresponde a uma pessoa detectada\n",
    "# com base nos seus id - 1 , ou seja, a pessoa de id 8, seu xyxy está em\n",
    "## xyxy[7]\n",
    "result.boxes.xyxy[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confianca da deteccao\n",
    "result.boxes.conf[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51974ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in result.boxes.id:\n",
    "    print(int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in result.boxes.id:\n",
    "    frames_detect_counter[int(id)] = frames_detect_counter[int(id)] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de30d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, qtde_frames in frames_detect_counter.items():\n",
    "    print(id, qtde_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_detect_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CONTAR O TEMPO EM QUE CADA UM FICOU NO VÍDEO\n",
    "\n",
    "para contar as pessoas, devo fazer um dicionario onde a chave é o id\n",
    "de cada pessoa e o dado eh um contador de frames. \n",
    "\n",
    "para cada frame, eu devo iterar pela lista de ids encontrados e atualizar \n",
    "o contador de cada Pessoa.\n",
    "\n",
    "Ao final, terei a quantidade de frames de cada pessoa no vídeo\n",
    "\n",
    "Basta chamar a função que converte isso para minutos, que retornará\n",
    "um dicionario ou lista com todos oS tempos desse ids \n",
    "\n",
    "chave = id, \n",
    "valor = tempo em horas, minutos e segundos\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(result.boxes.xywh[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a22795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
